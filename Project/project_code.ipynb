{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "33aace3f",
   "metadata": {},
   "source": [
    "# ANÁLISIS DIAGNÓSTICO: Estructura de los CSVs\n",
    "\n",
    "Primero, vamos a entender exactamente cómo están estructurados los archivos CSV para encontrar el problema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "767aabfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cargando archivos...\n",
      "\n",
      "=== TRAIN ===\n",
      "Shape: (145063, 551)\n",
      "Columnas: ['Page', '2015-07-01', '2015-07-02', '2015-07-03', '2015-07-04', '2015-07-05', '2015-07-06', '2015-07-07', '2015-07-08', '2015-07-09']... (551 total)\n",
      "\n",
      "Primeras 5 páginas:\n",
      "['2NE1_zh.wikipedia.org_all-access_spider', '2PM_zh.wikipedia.org_all-access_spider', '3C_zh.wikipedia.org_all-access_spider', '4minute_zh.wikipedia.org_all-access_spider', '52_Hz_I_Love_You_zh.wikipedia.org_all-access_spider']\n",
      "\n",
      "=== KEY ===\n",
      "Shape: (8703780, 2)\n",
      "Columnas: ['Page', 'Id']\n",
      "\n",
      "Primeras 10 filas:\n",
      "                                                Page            Id\n",
      "0  !vote_en.wikipedia.org_all-access_all-agents_2...  bf4edcf969af\n",
      "1  !vote_en.wikipedia.org_all-access_all-agents_2...  929ed2bf52b9\n",
      "2  !vote_en.wikipedia.org_all-access_all-agents_2...  ff29d0f51d5c\n",
      "3  !vote_en.wikipedia.org_all-access_all-agents_2...  e98873359be6\n",
      "4  !vote_en.wikipedia.org_all-access_all-agents_2...  fa012434263a\n",
      "5  !vote_en.wikipedia.org_all-access_all-agents_2...  48f1e93517a2\n",
      "6  !vote_en.wikipedia.org_all-access_all-agents_2...  5def418fcb36\n",
      "7  !vote_en.wikipedia.org_all-access_all-agents_2...  77bd08134351\n",
      "8  !vote_en.wikipedia.org_all-access_all-agents_2...  5889e6dbb16f\n",
      "9  !vote_en.wikipedia.org_all-access_all-agents_2...  5f21fef1d764\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Cargar archivos\n",
    "print(\"Cargando archivos...\")\n",
    "train = pd.read_csv('./muestra/train_1.csv')\n",
    "key = pd.read_csv('./muestra/key_1.csv')\n",
    "\n",
    "print(f\"\\n=== TRAIN ===\")\n",
    "print(f\"Shape: {train.shape}\")\n",
    "print(f\"Columnas: {train.columns[:10].tolist()}... ({len(train.columns)} total)\")\n",
    "print(f\"\\nPrimeras 5 páginas:\")\n",
    "print(train['Page'].head(5).tolist())\n",
    "\n",
    "print(f\"\\n=== KEY ===\")\n",
    "print(f\"Shape: {key.shape}\")\n",
    "print(f\"Columnas: {key.columns.tolist()}\")\n",
    "print(f\"\\nPrimeras 10 filas:\")\n",
    "print(key.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7f2d2d09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== PÁGINA COMPLETA DE KEY ===\n",
      "Length: 55\n",
      "Full: !vote_en.wikipedia.org_all-access_all-agents_2017-01-01\n",
      "\n",
      "=== PRIMERAS 5 PÁGINAS DE KEY (COMPLETAS) ===\n",
      "0: !vote_en.wikipedia.org_all-access_all-agents_2017-01-01\n",
      "1: !vote_en.wikipedia.org_all-access_all-agents_2017-01-02\n",
      "2: !vote_en.wikipedia.org_all-access_all-agents_2017-01-03\n",
      "3: !vote_en.wikipedia.org_all-access_all-agents_2017-01-04\n",
      "4: !vote_en.wikipedia.org_all-access_all-agents_2017-01-05\n",
      "\n",
      "=== ANÁLISIS DE ESTRUCTURA ===\n",
      "Sample page: !vote_en.wikipedia.org_all-access_spider_2017-02-10\n",
      "Length: 51\n",
      "Últimos 10 chars: '2017-02-10'\n",
      "Últimos 20 chars: 'ss_spider_2017-02-10'\n",
      "\n",
      "=== PRIMERAS 10 PÁGINAS DE TRAIN ===\n",
      "0: 2NE1_zh.wikipedia.org_all-access_spider\n",
      "1: 2PM_zh.wikipedia.org_all-access_spider\n",
      "2: 3C_zh.wikipedia.org_all-access_spider\n",
      "3: 4minute_zh.wikipedia.org_all-access_spider\n",
      "4: 52_Hz_I_Love_You_zh.wikipedia.org_all-access_spider\n",
      "5: 5566_zh.wikipedia.org_all-access_spider\n",
      "6: 91Days_zh.wikipedia.org_all-access_spider\n",
      "7: A'N'D_zh.wikipedia.org_all-access_spider\n",
      "8: AKB48_zh.wikipedia.org_all-access_spider\n",
      "9: ASCII_zh.wikipedia.org_all-access_spider\n"
     ]
    }
   ],
   "source": [
    "# Ver una página completa de key (sin truncamiento)\n",
    "print(\"=== PÁGINA COMPLETA DE KEY ===\")\n",
    "sample_key_page = key['Page'].iloc[0]\n",
    "print(f\"Length: {len(sample_key_page)}\")\n",
    "print(f\"Full: {sample_key_page}\")\n",
    "\n",
    "# Ver 5 páginas de key\n",
    "print(\"\\n=== PRIMERAS 5 PÁGINAS DE KEY (COMPLETAS) ===\")\n",
    "for i, page in enumerate(key['Page'].head(5)):\n",
    "    print(f\"{i}: {page}\")\n",
    "\n",
    "# Analizar estructura - ver si hay fecha al final\n",
    "print(\"\\n=== ANÁLISIS DE ESTRUCTURA ===\")\n",
    "sample = key['Page'].iloc[100]\n",
    "print(f\"Sample page: {sample}\")\n",
    "print(f\"Length: {len(sample)}\")\n",
    "print(f\"Últimos 10 chars: '{sample[-10:]}'\")\n",
    "print(f\"Últimos 20 chars: '{sample[-20:]}'\")\n",
    "\n",
    "# Ver algunas páginas de train\n",
    "print(\"\\n=== PRIMERAS 10 PÁGINAS DE TRAIN ===\")\n",
    "for i, page in enumerate(train['Page'].head(10)):\n",
    "    print(f\"{i}: {page}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "47aeba9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== BÚSQUEDA DE COINCIDENCIAS ===\n",
      "Bases únicas en key: 145063\n",
      "\n",
      "Primeras 5 bases únicas en key:\n",
      "['!vote_en.wikipedia.org_all-access_all-agents'\n",
      " '!vote_en.wikipedia.org_all-access_spider'\n",
      " '!vote_en.wikipedia.org_desktop_all-agents'\n",
      " '????:Andrey_Belloly_1.jpg_ru.wikipedia.org_all-access_all-agents'\n",
      " '????:Andrey_Belloly_1.jpg_ru.wikipedia.org_all-access_spider']\n",
      "\n",
      "=== RESULTADOS ===\n",
      "Coincidencias encontradas: 145063\n",
      "\n",
      "Primeras 10 coincidencias:\n",
      "  1: Help:Contents/id_www.mediawiki.org_desktop_all-agents\n",
      "  2: Decathlon_en.wikipedia.org_all-access_spider\n",
      "  3: 射龍門_(撲克遊戲)_zh.wikipedia.org_all-access_all-agents\n",
      "  4: 篠原涼子_ja.wikipedia.org_mobile-web_all-agents\n",
      "  5: Ernest_Sheepshanks_en.wikipedia.org_all-access_all-agents\n",
      "  6: Julian_Draxler_de.wikipedia.org_all-access_spider\n",
      "  7: File:WLE_Austria_Logo_(transparent).svg_commons.wikimedia.org_all-access_spider\n",
      "  8: Hardy_Krüger_de.wikipedia.org_mobile-web_all-agents\n",
      "  9: Beyoncé_en.wikipedia.org_desktop_all-agents\n",
      "  10: 駿河太郎_ja.wikipedia.org_desktop_all-agents\n",
      "\n",
      "✓ Página seleccionada para predicción: Help:Contents/id_www.mediawiki.org_desktop_all-agents\n",
      "\n",
      "Esta página existe en train: True\n",
      "Registros en key para esta página: 60\n"
     ]
    }
   ],
   "source": [
    "# Estrategia: extraer el nombre base de key (sin la fecha al final)\n",
    "# y buscar si existe en train\n",
    "\n",
    "print(\"=== BÚSQUEDA DE COINCIDENCIAS ===\")\n",
    "\n",
    "# Extraer base de key (quitando la fecha _YYYY-MM-DD)\n",
    "# Usar apply en lugar de str.rsplit para evitar problemas de sintaxis\n",
    "key['Page_Base'] = key['Page'].apply(lambda x: x.rsplit('_', 1)[0])\n",
    "\n",
    "print(f\"Bases únicas en key: {key['Page_Base'].nunique()}\")\n",
    "print(f\"\\nPrimeras 5 bases únicas en key:\")\n",
    "print(key['Page_Base'].unique()[:5])\n",
    "\n",
    "# Crear conjunto de páginas de train (son las bases directas)\n",
    "train_pages_set = set(train['Page'].unique())\n",
    "\n",
    "# Buscar coincidencias\n",
    "key_bases_set = set(key['Page_Base'].unique())\n",
    "\n",
    "matches = key_bases_set & train_pages_set\n",
    "print(f\"\\n=== RESULTADOS ===\")\n",
    "print(f\"Coincidencias encontradas: {len(matches)}\")\n",
    "\n",
    "if matches:\n",
    "    print(f\"\\nPrimeras 10 coincidencias:\")\n",
    "    for i, match in enumerate(list(matches)[:10]):\n",
    "        print(f\"  {i+1}: {match}\")\n",
    "    \n",
    "    # Tomar la primera coincidencia\n",
    "    nombre_pagina = list(matches)[0]\n",
    "    print(f\"\\n✓ Página seleccionada para predicción: {nombre_pagina}\")\n",
    "else:\n",
    "    print(\"\\n⚠ NO HAY COINCIDENCIAS EXACTAS\")\n",
    "    print(\"Estrategia alternativa: usar la primera página de train\")\n",
    "    nombre_pagina = train['Page'].iloc[0]\n",
    "    print(f\"✓ Página seleccionada: {nombre_pagina}\")\n",
    "    \n",
    "print(f\"\\nEsta página existe en train: {nombre_pagina in train_pages_set}\")\n",
    "print(f\"Registros en key para esta página: {(key['Page_Base'] == nombre_pagina).sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c6b2f1d",
   "metadata": {},
   "source": [
    "# Web Traffic Time Series Forecasting\n",
    "\n",
    "## Objetivos\n",
    "Este notebook realiza predicciones de tráfico web para una página utilizando un modelo de Regresión Lineal entrenado con datos históricos.\n",
    "\n",
    "### Pasos principales:\n",
    "1. **Carga de datos**: Se cargan los archivos CSV de entrenamiento (train) y prueba (key)\n",
    "2. **Búsqueda de coincidencias**: Se encuentra una página que existe en ambos conjuntos de datos\n",
    "3. **Preprocesamiento**: Se extrae la serie temporal y se convierten las fechas\n",
    "4. **Entrenamiento**: Se entrena un modelo de regresión lineal\n",
    "5. **Predicción**: Se generan predicciones para las fechas futuras\n",
    "6. **Salida**: Se guarda el resultado en un CSV de submission"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a36e6763",
   "metadata": {},
   "source": [
    "## 1. Importar librerías y configurar rutas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bdfee58",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Configuración de rutas\n",
    "RUTA_DATA = './muestra'          \n",
    "RUTA_SALIDA = './submissions' \n",
    "\n",
    "ARCHIVO_TRAIN = 'train_1.csv'  \n",
    "ARCHIVO_KEY = 'key_1.csv'\n",
    "ARCHIVO_SUBMISSION = 'submission_un_caso_final.csv'\n",
    "\n",
    "# Crear carpeta de salida si no existe\n",
    "os.makedirs(RUTA_SALIDA, exist_ok=True)\n",
    "\n",
    "print(\"--- INICIANDO PROCESO SISTÉMICO (CORRECCIÓN DEFINITIVA DE LÓGICA) ---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c28076e",
   "metadata": {},
   "source": [
    "## 2. Cargar datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afc853b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_train = os.path.join(RUTA_DATA, ARCHIVO_TRAIN)\n",
    "path_key = os.path.join(RUTA_DATA, ARCHIVO_KEY)\n",
    "\n",
    "print(f\"Cargando archivos CSV desde: {RUTA_DATA}...\")\n",
    "\n",
    "try:\n",
    "    train_df = pd.read_csv(path_train)\n",
    "    key_df = pd.read_csv(path_key)\n",
    "    print(f\"✓ Train cargado: {train_df.shape}\")\n",
    "    print(f\"✓ Key cargado: {key_df.shape}\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"¡ERROR DE RUTA! Archivos no encontrados.\")\n",
    "    exit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c624dc1",
   "metadata": {},
   "source": [
    "## 3. Buscar una página en común\n",
    "\n",
    "Se busca una página que exista en ambos conjuntos de datos (train y key). \n",
    "La lógica extrae el nombre base eliminando la fecha con `rsplit('_', 1)[0]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ac21f40",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\">> Buscando una página con datos en ambos sets (Train y Key)...\")\n",
    "\n",
    "# 1. Obtener una lista de páginas base del archivo KEY (sin la fecha)\n",
    "# CORRECCIÓN DEFINITIVA: rsplit('_', 1)[0] elimina solo el último '_Fecha'\n",
    "paginas_en_llave = key_df['Page'].apply(lambda x: x.rsplit('_', 1)[0]).unique()\n",
    "\n",
    "# 2. Buscar la primera página del TRAIN que coincida\n",
    "nombre_pagina = None\n",
    "for page_name_train in train_df['Page']:\n",
    "    page_base_name = page_name_train\n",
    "    \n",
    "    # Comprobamos si el nombre base del train existe en la lista de nombres base de la llave\n",
    "    if page_base_name in paginas_en_llave:\n",
    "        nombre_pagina = page_name_train\n",
    "        break\n",
    "\n",
    "if nombre_pagina is None:\n",
    "    # Si este error persiste, significa que las 500 páginas de train y key no se cruzan.\n",
    "    print(\"¡ERROR FATAL! No se encontró NINGUNA página en común para el análisis de 'un caso único'.\")\n",
    "    print(\"La lógica de comparación es correcta. Revisa si los sets de datos de muestra son complementarios.\")\n",
    "    exit()\n",
    "\n",
    "print(f\"\\n>> Página seleccionada: {nombre_pagina}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e8ec45d",
   "metadata": {},
   "source": [
    "## 4. Extracción y preprocesamiento de la serie temporal\n",
    "\n",
    "Se extrae la serie histórica de visitas y se convierten las fechas al formato correcto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2322812",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracción y preprocesamiento de la serie temporal\n",
    "pagina_objetivo = train_df[train_df['Page'] == nombre_pagina].iloc[0]\n",
    "serie_temporal = pagina_objetivo.drop('Page')\n",
    "serie_temporal.index = pd.to_datetime(serie_temporal.index)\n",
    "serie_temporal = pd.to_numeric(serie_temporal, errors='coerce').fillna(0) \n",
    "\n",
    "df_model = pd.DataFrame({'visitas': serie_temporal})\n",
    "df_model['dias'] = (df_model.index - df_model.index[0]).days\n",
    "\n",
    "print(f\"✓ Serie temporal: {len(df_model)} observaciones\")\n",
    "print(f\"✓ Rango de fechas: {df_model.index[0].date()} a {df_model.index[-1].date()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8022dc26",
   "metadata": {},
   "source": [
    "## 5. Entrenamiento del modelo\n",
    "\n",
    "Se entrena un modelo de **Regresión Lineal** utilizando los días como característica y las visitas como variable objetivo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b75c5f8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df_model[['dias']].values\n",
    "y_train = df_model['visitas'].values\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "print(f\"✓ Modelo entrenado\")\n",
    "print(f\"  - Coeficiente (pendiente): {model.coef_[0]:.6f}\")\n",
    "print(f\"  - Intersección: {model.intercept_:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b82f8630",
   "metadata": {},
   "source": [
    "## 6. Generación de predicciones\n",
    "\n",
    "Se realizan predicciones para las fechas futuras en el conjunto de prueba (key)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc66f40c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\">> Generando predicciones para el periodo requerido...\")\n",
    "\n",
    "# Filtramos solo las llaves que corresponden a nuestra página objetivo\n",
    "llaves_caso = key_df[key_df['Page'].str.startswith(nombre_pagina, na=False)].copy()\n",
    "\n",
    "# Cálculo de días futuros\n",
    "llaves_caso['Fecha'] = pd.to_datetime(llaves_caso['Page'].apply(lambda x: x[-10:]))\n",
    "fecha_inicio = df_model.index[0]\n",
    "dias_futuros = (llaves_caso['Fecha'] - fecha_inicio).days.values.reshape(-1, 1)\n",
    "\n",
    "# Realizar predicciones\n",
    "predicciones = model.predict(dias_futuros)\n",
    "predicciones = np.maximum(predicciones, 0)  # Asegurar valores no negativos\n",
    "\n",
    "print(f\"✓ Predicciones generadas: {len(predicciones)} registros\")\n",
    "print(f\"✓ Rango de predicciones: {predicciones.min():.2f} a {predicciones.max():.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c60fa787",
   "metadata": {},
   "source": [
    "## 7. Guardar resultados\n",
    "\n",
    "Se crea un DataFrame con los IDs y las predicciones, y se guarda en un archivo CSV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc9497b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({\n",
    "    'Id': llaves_caso['Id'],\n",
    "    'Visits': predicciones\n",
    "})\n",
    "\n",
    "path_guardado = os.path.join(RUTA_SALIDA, ARCHIVO_SUBMISSION)\n",
    "submission.to_csv(path_guardado, index=False)\n",
    "\n",
    "print(f\"\\n>> ¡PROCESO FINALIZADO CON ÉXITO!\")\n",
    "print(f\"Archivo de submission para '{nombre_pagina}' guardado en: {path_guardado}\")\n",
    "print(\"\\nMuestra de la salida:\")\n",
    "print(submission.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c330f323",
   "metadata": {},
   "source": [
    "## Análisis de Coincidencias CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "56a6d557",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CONTANDO FILAS EN TRAIN_1.CSV...\n",
      "Total de filas en train_1.csv: 145,063\n",
      "\n",
      "CONTANDO FILAS EN KEY_1.CSV...\n",
      "Total de filas en key_1.csv: 8,703,780\n"
     ]
    }
   ],
   "source": [
    "# Primero contar líneas sin cargar en memoria\n",
    "train_path = 'muestra/train_1.csv'\n",
    "key_path = 'muestra/key_1.csv'\n",
    "\n",
    "print(\"CONTANDO FILAS EN TRAIN_1.CSV...\")\n",
    "with open(train_path, 'r', encoding='utf-8', errors='ignore') as f:\n",
    "    train_lines = sum(1 for _ in f) - 1\n",
    "\n",
    "print(f\"Total de filas en train_1.csv: {train_lines:,}\")\n",
    "\n",
    "print(\"\\nCONTANDO FILAS EN KEY_1.CSV...\")\n",
    "with open(key_path, 'r', encoding='utf-8', errors='ignore') as f:\n",
    "    key_lines = sum(1 for _ in f) - 1\n",
    "\n",
    "print(f\"Total de filas en key_1.csv: {key_lines:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "893dcfc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "====================================================================================================\n",
      "CARGANDO ARCHIVOS PARA ANÁLISIS\n",
      "====================================================================================================\n",
      "\n",
      "Cargando train_1.csv (primeras 500 filas)...\n",
      "✓ Cargado\n",
      "Cargando key_1.csv completo...\n",
      "✓ Cargado (8,703,780 filas)\n",
      "\n",
      "====================================================================================================\n",
      "ESTRUCTURA DE LOS ARCHIVOS\n",
      "====================================================================================================\n",
      "\n",
      "TRAIN_1.CSV (muestra de 500 filas):\n",
      "  Columnas: ['Page', '2015-07-01', '2015-07-02', '2015-07-03', '2015-07-04', '2015-07-05', '2015-07-06', '2015-07-07', '2015-07-08', '2015-07-09', '2015-07-10', '2015-07-11', '2015-07-12', '2015-07-13', '2015-07-14', '2015-07-15', '2015-07-16', '2015-07-17', '2015-07-18', '2015-07-19', '2015-07-20', '2015-07-21', '2015-07-22', '2015-07-23', '2015-07-24', '2015-07-25', '2015-07-26', '2015-07-27', '2015-07-28', '2015-07-29', '2015-07-30', '2015-07-31', '2015-08-01', '2015-08-02', '2015-08-03', '2015-08-04', '2015-08-05', '2015-08-06', '2015-08-07', '2015-08-08', '2015-08-09', '2015-08-10', '2015-08-11', '2015-08-12', '2015-08-13', '2015-08-14', '2015-08-15', '2015-08-16', '2015-08-17', '2015-08-18', '2015-08-19', '2015-08-20', '2015-08-21', '2015-08-22', '2015-08-23', '2015-08-24', '2015-08-25', '2015-08-26', '2015-08-27', '2015-08-28', '2015-08-29', '2015-08-30', '2015-08-31', '2015-09-01', '2015-09-02', '2015-09-03', '2015-09-04', '2015-09-05', '2015-09-06', '2015-09-07', '2015-09-08', '2015-09-09', '2015-09-10', '2015-09-11', '2015-09-12', '2015-09-13', '2015-09-14', '2015-09-15', '2015-09-16', '2015-09-17', '2015-09-18', '2015-09-19', '2015-09-20', '2015-09-21', '2015-09-22', '2015-09-23', '2015-09-24', '2015-09-25', '2015-09-26', '2015-09-27', '2015-09-28', '2015-09-29', '2015-09-30', '2015-10-01', '2015-10-02', '2015-10-03', '2015-10-04', '2015-10-05', '2015-10-06', '2015-10-07', '2015-10-08', '2015-10-09', '2015-10-10', '2015-10-11', '2015-10-12', '2015-10-13', '2015-10-14', '2015-10-15', '2015-10-16', '2015-10-17', '2015-10-18', '2015-10-19', '2015-10-20', '2015-10-21', '2015-10-22', '2015-10-23', '2015-10-24', '2015-10-25', '2015-10-26', '2015-10-27', '2015-10-28', '2015-10-29', '2015-10-30', '2015-10-31', '2015-11-01', '2015-11-02', '2015-11-03', '2015-11-04', '2015-11-05', '2015-11-06', '2015-11-07', '2015-11-08', '2015-11-09', '2015-11-10', '2015-11-11', '2015-11-12', '2015-11-13', '2015-11-14', '2015-11-15', '2015-11-16', '2015-11-17', '2015-11-18', '2015-11-19', '2015-11-20', '2015-11-21', '2015-11-22', '2015-11-23', '2015-11-24', '2015-11-25', '2015-11-26', '2015-11-27', '2015-11-28', '2015-11-29', '2015-11-30', '2015-12-01', '2015-12-02', '2015-12-03', '2015-12-04', '2015-12-05', '2015-12-06', '2015-12-07', '2015-12-08', '2015-12-09', '2015-12-10', '2015-12-11', '2015-12-12', '2015-12-13', '2015-12-14', '2015-12-15', '2015-12-16', '2015-12-17', '2015-12-18', '2015-12-19', '2015-12-20', '2015-12-21', '2015-12-22', '2015-12-23', '2015-12-24', '2015-12-25', '2015-12-26', '2015-12-27', '2015-12-28', '2015-12-29', '2015-12-30', '2015-12-31', '2016-01-01', '2016-01-02', '2016-01-03', '2016-01-04', '2016-01-05', '2016-01-06', '2016-01-07', '2016-01-08', '2016-01-09', '2016-01-10', '2016-01-11', '2016-01-12', '2016-01-13', '2016-01-14', '2016-01-15', '2016-01-16', '2016-01-17', '2016-01-18', '2016-01-19', '2016-01-20', '2016-01-21', '2016-01-22', '2016-01-23', '2016-01-24', '2016-01-25', '2016-01-26', '2016-01-27', '2016-01-28', '2016-01-29', '2016-01-30', '2016-01-31', '2016-02-01', '2016-02-02', '2016-02-03', '2016-02-04', '2016-02-05', '2016-02-06', '2016-02-07', '2016-02-08', '2016-02-09', '2016-02-10', '2016-02-11', '2016-02-12', '2016-02-13', '2016-02-14', '2016-02-15', '2016-02-16', '2016-02-17', '2016-02-18', '2016-02-19', '2016-02-20', '2016-02-21', '2016-02-22', '2016-02-23', '2016-02-24', '2016-02-25', '2016-02-26', '2016-02-27', '2016-02-28', '2016-02-29', '2016-03-01', '2016-03-02', '2016-03-03', '2016-03-04', '2016-03-05', '2016-03-06', '2016-03-07', '2016-03-08', '2016-03-09', '2016-03-10', '2016-03-11', '2016-03-12', '2016-03-13', '2016-03-14', '2016-03-15', '2016-03-16', '2016-03-17', '2016-03-18', '2016-03-19', '2016-03-20', '2016-03-21', '2016-03-22', '2016-03-23', '2016-03-24', '2016-03-25', '2016-03-26', '2016-03-27', '2016-03-28', '2016-03-29', '2016-03-30', '2016-03-31', '2016-04-01', '2016-04-02', '2016-04-03', '2016-04-04', '2016-04-05', '2016-04-06', '2016-04-07', '2016-04-08', '2016-04-09', '2016-04-10', '2016-04-11', '2016-04-12', '2016-04-13', '2016-04-14', '2016-04-15', '2016-04-16', '2016-04-17', '2016-04-18', '2016-04-19', '2016-04-20', '2016-04-21', '2016-04-22', '2016-04-23', '2016-04-24', '2016-04-25', '2016-04-26', '2016-04-27', '2016-04-28', '2016-04-29', '2016-04-30', '2016-05-01', '2016-05-02', '2016-05-03', '2016-05-04', '2016-05-05', '2016-05-06', '2016-05-07', '2016-05-08', '2016-05-09', '2016-05-10', '2016-05-11', '2016-05-12', '2016-05-13', '2016-05-14', '2016-05-15', '2016-05-16', '2016-05-17', '2016-05-18', '2016-05-19', '2016-05-20', '2016-05-21', '2016-05-22', '2016-05-23', '2016-05-24', '2016-05-25', '2016-05-26', '2016-05-27', '2016-05-28', '2016-05-29', '2016-05-30', '2016-05-31', '2016-06-01', '2016-06-02', '2016-06-03', '2016-06-04', '2016-06-05', '2016-06-06', '2016-06-07', '2016-06-08', '2016-06-09', '2016-06-10', '2016-06-11', '2016-06-12', '2016-06-13', '2016-06-14', '2016-06-15', '2016-06-16', '2016-06-17', '2016-06-18', '2016-06-19', '2016-06-20', '2016-06-21', '2016-06-22', '2016-06-23', '2016-06-24', '2016-06-25', '2016-06-26', '2016-06-27', '2016-06-28', '2016-06-29', '2016-06-30', '2016-07-01', '2016-07-02', '2016-07-03', '2016-07-04', '2016-07-05', '2016-07-06', '2016-07-07', '2016-07-08', '2016-07-09', '2016-07-10', '2016-07-11', '2016-07-12', '2016-07-13', '2016-07-14', '2016-07-15', '2016-07-16', '2016-07-17', '2016-07-18', '2016-07-19', '2016-07-20', '2016-07-21', '2016-07-22', '2016-07-23', '2016-07-24', '2016-07-25', '2016-07-26', '2016-07-27', '2016-07-28', '2016-07-29', '2016-07-30', '2016-07-31', '2016-08-01', '2016-08-02', '2016-08-03', '2016-08-04', '2016-08-05', '2016-08-06', '2016-08-07', '2016-08-08', '2016-08-09', '2016-08-10', '2016-08-11', '2016-08-12', '2016-08-13', '2016-08-14', '2016-08-15', '2016-08-16', '2016-08-17', '2016-08-18', '2016-08-19', '2016-08-20', '2016-08-21', '2016-08-22', '2016-08-23', '2016-08-24', '2016-08-25', '2016-08-26', '2016-08-27', '2016-08-28', '2016-08-29', '2016-08-30', '2016-08-31', '2016-09-01', '2016-09-02', '2016-09-03', '2016-09-04', '2016-09-05', '2016-09-06', '2016-09-07', '2016-09-08', '2016-09-09', '2016-09-10', '2016-09-11', '2016-09-12', '2016-09-13', '2016-09-14', '2016-09-15', '2016-09-16', '2016-09-17', '2016-09-18', '2016-09-19', '2016-09-20', '2016-09-21', '2016-09-22', '2016-09-23', '2016-09-24', '2016-09-25', '2016-09-26', '2016-09-27', '2016-09-28', '2016-09-29', '2016-09-30', '2016-10-01', '2016-10-02', '2016-10-03', '2016-10-04', '2016-10-05', '2016-10-06', '2016-10-07', '2016-10-08', '2016-10-09', '2016-10-10', '2016-10-11', '2016-10-12', '2016-10-13', '2016-10-14', '2016-10-15', '2016-10-16', '2016-10-17', '2016-10-18', '2016-10-19', '2016-10-20', '2016-10-21', '2016-10-22', '2016-10-23', '2016-10-24', '2016-10-25', '2016-10-26', '2016-10-27', '2016-10-28', '2016-10-29', '2016-10-30', '2016-10-31', '2016-11-01', '2016-11-02', '2016-11-03', '2016-11-04', '2016-11-05', '2016-11-06', '2016-11-07', '2016-11-08', '2016-11-09', '2016-11-10', '2016-11-11', '2016-11-12', '2016-11-13', '2016-11-14', '2016-11-15', '2016-11-16', '2016-11-17', '2016-11-18', '2016-11-19', '2016-11-20', '2016-11-21', '2016-11-22', '2016-11-23', '2016-11-24', '2016-11-25', '2016-11-26', '2016-11-27', '2016-11-28', '2016-11-29', '2016-11-30', '2016-12-01', '2016-12-02', '2016-12-03', '2016-12-04', '2016-12-05', '2016-12-06', '2016-12-07', '2016-12-08', '2016-12-09', '2016-12-10', '2016-12-11', '2016-12-12', '2016-12-13', '2016-12-14', '2016-12-15', '2016-12-16', '2016-12-17', '2016-12-18', '2016-12-19', '2016-12-20', '2016-12-21', '2016-12-22', '2016-12-23', '2016-12-24', '2016-12-25', '2016-12-26', '2016-12-27', '2016-12-28', '2016-12-29', '2016-12-30', '2016-12-31']\n",
      "  Forma: (500, 551)\n",
      "\n",
      "KEY_1.CSV:\n",
      "  Columnas: ['Page', 'Id']\n",
      "  Forma: (8703780, 2)\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "PRIMERAS FILAS DE TRAIN_1.CSV:\n",
      "----------------------------------------------------------------------------------------------------\n",
      "                                                Page  2015-07-01  2015-07-02  \\\n",
      "0            2NE1_zh.wikipedia.org_all-access_spider        18.0        11.0   \n",
      "1             2PM_zh.wikipedia.org_all-access_spider        11.0        14.0   \n",
      "2              3C_zh.wikipedia.org_all-access_spider         1.0         0.0   \n",
      "3         4minute_zh.wikipedia.org_all-access_spider        35.0        13.0   \n",
      "4  52_Hz_I_Love_You_zh.wikipedia.org_all-access_s...         NaN         NaN   \n",
      "5            5566_zh.wikipedia.org_all-access_spider        12.0         7.0   \n",
      "6          91Days_zh.wikipedia.org_all-access_spider         NaN         NaN   \n",
      "7           A'N'D_zh.wikipedia.org_all-access_spider       118.0        26.0   \n",
      "8           AKB48_zh.wikipedia.org_all-access_spider         5.0        23.0   \n",
      "9           ASCII_zh.wikipedia.org_all-access_spider         6.0         3.0   \n",
      "\n",
      "   2015-07-03  2015-07-04  2015-07-05  2015-07-06  2015-07-07  2015-07-08  \\\n",
      "0         5.0        13.0        14.0         9.0         9.0        22.0   \n",
      "1        15.0        18.0        11.0        13.0        22.0        11.0   \n",
      "2         1.0         1.0         0.0         4.0         0.0         3.0   \n",
      "3        10.0        94.0         4.0        26.0        14.0         9.0   \n",
      "4         NaN         NaN         NaN         NaN         NaN         NaN   \n",
      "5         4.0         5.0        20.0         8.0         5.0        17.0   \n",
      "6         NaN         NaN         NaN         NaN         NaN         NaN   \n",
      "7        30.0        24.0        29.0       127.0        53.0        37.0   \n",
      "8        14.0        12.0         9.0         9.0        35.0        15.0   \n",
      "9         5.0        12.0         6.0         5.0         4.0        13.0   \n",
      "\n",
      "   2015-07-09  ...  2016-12-22  2016-12-23  2016-12-24  2016-12-25  \\\n",
      "0        26.0  ...        32.0        63.0        15.0        26.0   \n",
      "1        10.0  ...        17.0        42.0        28.0        15.0   \n",
      "2         4.0  ...         3.0         1.0         1.0         7.0   \n",
      "3        11.0  ...        32.0        10.0        26.0        27.0   \n",
      "4         NaN  ...        48.0         9.0        25.0        13.0   \n",
      "5        24.0  ...        16.0        27.0         8.0        17.0   \n",
      "6         NaN  ...         2.0         7.0        33.0         8.0   \n",
      "7        20.0  ...        64.0        35.0        35.0        28.0   \n",
      "8        14.0  ...        34.0       105.0        72.0        36.0   \n",
      "9         9.0  ...        25.0        17.0        22.0        29.0   \n",
      "\n",
      "   2016-12-26  2016-12-27  2016-12-28  2016-12-29  2016-12-30  2016-12-31  \n",
      "0        14.0        20.0        22.0        19.0        18.0        20.0  \n",
      "1         9.0        30.0        52.0        45.0        26.0        20.0  \n",
      "2         4.0         4.0         6.0         3.0         4.0        17.0  \n",
      "3        16.0        11.0        17.0        19.0        10.0        11.0  \n",
      "4         3.0        11.0        27.0        13.0        36.0        10.0  \n",
      "5        32.0        19.0        23.0        17.0        17.0        50.0  \n",
      "6        11.0         4.0        15.0         6.0         8.0         6.0  \n",
      "7        20.0        23.0        32.0        39.0        32.0        17.0  \n",
      "8        33.0        30.0        36.0        38.0        31.0        97.0  \n",
      "9        30.0        29.0        35.0        44.0        26.0        41.0  \n",
      "\n",
      "[10 rows x 551 columns]\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "PRIMERAS FILAS DE KEY_1.CSV:\n",
      "----------------------------------------------------------------------------------------------------\n",
      "                                                Page            Id\n",
      "0  !vote_en.wikipedia.org_all-access_all-agents_2...  bf4edcf969af\n",
      "1  !vote_en.wikipedia.org_all-access_all-agents_2...  929ed2bf52b9\n",
      "2  !vote_en.wikipedia.org_all-access_all-agents_2...  ff29d0f51d5c\n",
      "3  !vote_en.wikipedia.org_all-access_all-agents_2...  e98873359be6\n",
      "4  !vote_en.wikipedia.org_all-access_all-agents_2...  fa012434263a\n",
      "5  !vote_en.wikipedia.org_all-access_all-agents_2...  48f1e93517a2\n",
      "6  !vote_en.wikipedia.org_all-access_all-agents_2...  5def418fcb36\n",
      "7  !vote_en.wikipedia.org_all-access_all-agents_2...  77bd08134351\n",
      "8  !vote_en.wikipedia.org_all-access_all-agents_2...  5889e6dbb16f\n",
      "9  !vote_en.wikipedia.org_all-access_all-agents_2...  5f21fef1d764\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "print(\"\\n\" + \"=\"*100)\n",
    "print(\"CARGANDO ARCHIVOS PARA ANÁLISIS\")\n",
    "print(\"=\"*100)\n",
    "\n",
    "# Cargar solo primeras filas de train para inspeccionar\n",
    "print(\"\\nCargando train_1.csv (primeras 500 filas)...\")\n",
    "train_sample = pd.read_csv(train_path, nrows=500)\n",
    "print(f\"✓ Cargado\")\n",
    "\n",
    "print(\"Cargando key_1.csv completo...\")\n",
    "key_df = pd.read_csv(key_path)\n",
    "print(f\"✓ Cargado ({len(key_df):,} filas)\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*100)\n",
    "print(\"ESTRUCTURA DE LOS ARCHIVOS\")\n",
    "print(\"=\"*100)\n",
    "\n",
    "print(f\"\\nTRAIN_1.CSV (muestra de 500 filas):\")\n",
    "print(f\"  Columnas: {list(train_sample.columns)}\")\n",
    "print(f\"  Forma: {train_sample.shape}\")\n",
    "\n",
    "print(f\"\\nKEY_1.CSV:\")\n",
    "print(f\"  Columnas: {list(key_df.columns)}\")\n",
    "print(f\"  Forma: {key_df.shape}\")\n",
    "\n",
    "print(\"\\n\" + \"-\"*100)\n",
    "print(\"PRIMERAS FILAS DE TRAIN_1.CSV:\")\n",
    "print(\"-\"*100)\n",
    "print(train_sample.head(10))\n",
    "\n",
    "print(\"\\n\" + \"-\"*100)\n",
    "print(\"PRIMERAS FILAS DE KEY_1.CSV:\")\n",
    "print(\"-\"*100)\n",
    "print(key_df.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "10a7c314",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "====================================================================================================\n",
      "ANÁLISIS DE LA COLUMNA IDENTIFICADORA\n",
      "====================================================================================================\n",
      "\n",
      "COLUMNA EN TRAIN: 'Page'\n",
      "  Valores únicos en muestra: 500\n",
      "  Primeros 15 valores únicos:\n",
      "    100毛_zh.wikipedia.org_all-access_spider\n",
      "    2016年3月9日日食_zh.wikipedia.org_all-access_spider\n",
      "    2016年夏季奧林匹克運動會_zh.wikipedia.org_all-access_spider\n",
      "    2016年美國總統選舉_zh.wikipedia.org_all-access_spider\n",
      "    2NE1_zh.wikipedia.org_all-access_spider\n",
      "    2PM_zh.wikipedia.org_all-access_spider\n",
      "    3C_zh.wikipedia.org_all-access_spider\n",
      "    4minute_zh.wikipedia.org_all-access_spider\n",
      "    52_Hz_I_Love_You_zh.wikipedia.org_all-access_spider\n",
      "    5566_zh.wikipedia.org_all-access_spider\n",
      "    700歲旅程_zh.wikipedia.org_all-access_spider\n",
      "    91Days_zh.wikipedia.org_all-access_spider\n",
      "    A'N'D_zh.wikipedia.org_all-access_spider\n",
      "    AKB48_zh.wikipedia.org_all-access_spider\n",
      "    ASCII_zh.wikipedia.org_all-access_spider\n",
      "\n",
      "COLUMNA EN KEY: 'Page'\n",
      "  Valores únicos: 8,703,780\n",
      "  Primeros 15 valores únicos:\n",
      "    !vote_en.wikipedia.org_all-access_all-agents_2017-01-01\n",
      "    !vote_en.wikipedia.org_all-access_all-agents_2017-01-02\n",
      "    !vote_en.wikipedia.org_all-access_all-agents_2017-01-03\n",
      "    !vote_en.wikipedia.org_all-access_all-agents_2017-01-04\n",
      "    !vote_en.wikipedia.org_all-access_all-agents_2017-01-05\n",
      "    !vote_en.wikipedia.org_all-access_all-agents_2017-01-06\n",
      "    !vote_en.wikipedia.org_all-access_all-agents_2017-01-07\n",
      "    !vote_en.wikipedia.org_all-access_all-agents_2017-01-08\n",
      "    !vote_en.wikipedia.org_all-access_all-agents_2017-01-09\n",
      "    !vote_en.wikipedia.org_all-access_all-agents_2017-01-10\n",
      "    !vote_en.wikipedia.org_all-access_all-agents_2017-01-11\n",
      "    !vote_en.wikipedia.org_all-access_all-agents_2017-01-12\n",
      "    !vote_en.wikipedia.org_all-access_all-agents_2017-01-13\n",
      "    !vote_en.wikipedia.org_all-access_all-agents_2017-01-14\n",
      "    !vote_en.wikipedia.org_all-access_all-agents_2017-01-15\n"
     ]
    }
   ],
   "source": [
    "# Analizar columnas identificadoras\n",
    "print(\"\\n\" + \"=\"*100)\n",
    "print(\"ANÁLISIS DE LA COLUMNA IDENTIFICADORA\")\n",
    "print(\"=\"*100)\n",
    "\n",
    "# Primera columna es el identificador\n",
    "train_id_col = train_sample.columns[0]\n",
    "key_id_col = key_df.columns[0]\n",
    "\n",
    "print(f\"\\nCOLUMNA EN TRAIN: '{train_id_col}'\")\n",
    "train_values = set(train_sample[train_id_col].astype(str).unique())\n",
    "print(f\"  Valores únicos en muestra: {len(train_values)}\")\n",
    "print(f\"  Primeros 15 valores únicos:\")\n",
    "for v in sorted(list(train_values))[:15]:\n",
    "    print(f\"    {v}\")\n",
    "\n",
    "print(f\"\\nCOLUMNA EN KEY: '{key_id_col}'\")\n",
    "key_values = set(key_df[key_id_col].astype(str).unique())\n",
    "print(f\"  Valores únicos: {len(key_values):,}\")\n",
    "print(f\"  Primeros 15 valores únicos:\")\n",
    "for v in sorted(list(key_values))[:15]:\n",
    "    print(f\"    {v}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
